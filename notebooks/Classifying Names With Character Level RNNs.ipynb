{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Names with a Character Level RNN\n",
    "\n",
    "In this tutorial we try to predict the nationality of a name by processing it through a bidirectional LSTM one character at a time. We have 18 input files, each corresponding to a different nationality. We will store the names in a dictionary of the form `{'Nationality': [name1, name2, ...], ...}`. The [`glob` module](https://docs.python.org/3/library/glob.html) is more convenient than `os.listdir` for this purpsose, as it returns the full path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/names/German.txt', '../data/names/Arabic.txt', '../data/names/Vietnamese.txt', '../data/names/Dutch.txt', '../data/names/Polish.txt', '../data/names/Portuguese.txt', '../data/names/Scottish.txt', '../data/names/Korean.txt', '../data/names/Irish.txt', '../data/names/Russian.txt', '../data/names/Czech.txt', '../data/names/Greek.txt', '../data/names/Italian.txt', '../data/names/Spanish.txt', '../data/names/French.txt', '../data/names/Japanese.txt', '../data/names/English.txt', '../data/names/Chinese.txt']\n"
     ]
    }
   ],
   "source": [
    "# from io import open\n",
    "import os\n",
    "import glob\n",
    "import string\n",
    "from functools import reduce\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "file_list = glob.glob('../data/names/*.txt')\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abbing', 'Abel', 'Abeln', 'Abt']\n",
      "dict_keys(['German', 'Arabic', 'Vietnamese', 'Dutch', 'Polish', 'Portuguese', 'Scottish', 'Korean', 'Irish', 'Russian', 'Czech', 'Greek', 'Italian', 'Spanish', 'French', 'Japanese', 'English', 'Chinese'])\n"
     ]
    }
   ],
   "source": [
    "category_lines = {}\n",
    "\n",
    "for file_name in file_list:\n",
    "    nationality = os.path.basename(os.path.splitext(file_name)[0])\n",
    "    name_list = []\n",
    "    for line in open(file_name, 'r'):\n",
    "        name_list.append(line.rstrip())\n",
    "    category_lines[nationality] = name_list\n",
    "\n",
    "print(category_lines['German'][:4])\n",
    "print(category_lines.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the names contain accents and other non-ASCII characters that can make things complicated. We may convert all the characters to plain ASCII, as shown in the vignette, but our task would probably be easier if we could account for the non-ASCII characters. Some characters, for exaample, are specific of Polish, so encountering one of such characters would be already a strong hint that the name is indeed Polish. Let's try this approach, which deviates from the one in the [tutorial](http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html). We read each file in turn, and for each file we extract the set of unique characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_characters(filename):\n",
    "    character_sets = []\n",
    "    for name in open(filename, 'r'):\n",
    "        character_sets.append(set(name.lower()))\n",
    "    unique_characters = reduce(set.union, character_sets)\n",
    "    return unique_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the first element of `file_list`, which contains the German names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d', 'm', 'e', 'q', 's', 'ß', 'h', 'y', 'v', 'b', 'f', 'c', 'z', 'p', 'l', 'j', 'a', 'r', 'k', '\\n', 'x', 'ü', 'n', 'u', 'o', 'g', 'ä', 'w', 't', ' ', 'i', 'ö'}\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "unique_german = get_unique_characters(file_list[0])\n",
    "print(unique_german)\n",
    "print(len(unique_german))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this method on all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d', 'e', 'q', 's', 'h', 'y', 'v', 'c', 'z', 'p', 'j', 'é', '\\xa0', 'r', 'ê', 'k', '\\n', 'x', 'ą', 'n', 'o', 'ì', 'ó', 'w', 'ł', 'á', 't', ' ', \"'\", 'õ', ':', 'm', '/', 'í', 'ß', 'ú', 'b', 'f', 'ã', 'ñ', 'l', 'ż', 'a', '1', 'ś', ',', 'è', 'ü', '-', 'u', 'g', 'ä', 'ù', 'i', 'ö', 'à', 'ò', 'ń', 'ç'}\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "all_unique_characters = [get_unique_characters(f) for f in file_list]\n",
    "all_unique_characters = reduce(set.union, all_unique_characters)\n",
    "print(all_unique_characters)\n",
    "print(len(all_unique_characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us all the characters appearing in the files. We can turn this into a dictionary to later create one-hot encodings of the individual characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': 0, 'e': 1, 'q': 2, 's': 3, 'h': 4, 'y': 5, 'v': 6, 'c': 7, 'z': 8, 'p': 9, 'j': 10, 'é': 11, '\\xa0': 12, 'r': 13, 'ê': 14, 'k': 15, '\\n': 16, 'x': 17, 'ą': 18, 'n': 19, 'o': 20, 'ì': 21, 'ó': 22, 'w': 23, 'ł': 24, 'á': 25, 't': 26, ' ': 27, \"'\": 28, 'õ': 29, ':': 30, 'm': 31, '/': 32, 'í': 33, 'ß': 34, 'ú': 35, 'b': 36, 'f': 37, 'ã': 38, 'ñ': 39, 'l': 40, 'ż': 41, 'a': 42, '1': 43, 'ś': 44, ',': 45, 'è': 46, 'ü': 47, '-': 48, 'u': 49, 'g': 50, 'ä': 51, 'ù': 52, 'i': 53, 'ö': 54, 'à': 55, 'ò': 56, 'ń': 57, 'ç': 58}\n"
     ]
    }
   ],
   "source": [
    "character_dict = {char: ix for ix, char in enumerate(all_unique_characters)}\n",
    "print(character_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a name classifier we need to turn the names into character tensors. In our dictionary there are 59 characters, so each name should be represented as a tensor of shape $(l_n, 1, 59)$, where $l_n$ is the length of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_tensor(name, dictionary=character_dict):\n",
    "    len_name = len(name)\n",
    "    len_dictionary = len(dictionary)\n",
    "    output = torch.zeros(len_name, len_dictionary)\n",
    "    for k in range(len_name):\n",
    "        output[k, dictionary[name[k]]] = 1\n",
    "    output = output.view(len_name, 1, len_dictionary)\n",
    "    return Variable(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if this function returns something sensible. We test on a fake surname consisting of the first three keys in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "\n",
       "Columns 0 to 18 \n",
       "    0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 19 to 37 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 38 to 56 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 57 to 58 \n",
       "    0   0\n",
       "\n",
       "(1 ,.,.) = \n",
       "\n",
       "Columns 0 to 18 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 19 to 37 \n",
       "    0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 38 to 56 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 57 to 58 \n",
       "    0   0\n",
       "\n",
       "(2 ,.,.) = \n",
       "\n",
       "Columns 0 to 18 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
       "\n",
       "Columns 19 to 37 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 38 to 56 \n",
       "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "\n",
       "Columns 57 to 58 \n",
       "    0   0\n",
       "[torch.FloatTensor of size 3x1x59]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_to_tensor('v x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to encode the nationality into a long tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationality_dict = {nationality: ix for ix, nationality in enumerate(category_lines.keys())}\n",
    "\n",
    "def nationality_to_tensor(nationality, dictionary=nationality_dict):\n",
    "    nationality_tensor = torch.LongTensor([dictionary[nationality]])\n",
    "    return Variable(nationality_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's check if this works. The first key is 'German', so the first element of the output should be a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'German': 0, 'Arabic': 1, 'Vietnamese': 2, 'Dutch': 3, 'Polish': 4, 'Portuguese': 5, 'Scottish': 6, 'Korean': 7, 'Irish': 8, 'Russian': 9, 'Czech': 10, 'Greek': 11, 'Italian': 12, 'Spanish': 13, 'French': 14, 'Japanese': 15, 'English': 16, 'Chinese': 17}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.LongTensor of size 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(nationality_dict)\n",
    "nationality_to_tensor('German')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [tutorial](http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) there are slightly different, and probably more efficient implementations, of these functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "We can now build one or more models to see how well (or badly) we perform on this task. We can start with a simple model with one single LSTM layer. Here we feed the one-hot encoded characters to the LSTM. There are a few things to note in this model:\n",
    "\n",
    "1. the `hidden_dim` parameter is stored in a class attribute for later use in `init_hidden`.\n",
    "2. `self.hidden` is initialized by `init_hidden` when we instantiate the class. The object we obtain is therefore already initialized.\n",
    "3. The `self.lstm_output` tensor still has shape (1, 1, num_nationalities). This is why we need to reshape it.\n",
    "\n",
    "Finally note that here we are making an experiment. We take the hidden state of the last step of the LSTM, and we feed it into the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim, vocabulary_size, num_nationalities):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_nationalities = num_nationalities\n",
    "        self.lstm = nn.LSTM(input_size=vocabulary_size, hidden_size=hidden_dim)\n",
    "        self.linear = nn.Linear(in_features=hidden_dim, out_features=num_nationalities)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(1, 1, self.hidden_dim)), \n",
    "                Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        lstm_output, lstm_hidden = self.lstm(inputs, self.hidden)\n",
    "        last_output = lstm_output[len(inputs) - 1]\n",
    "        output = self.linear(last_output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate this class and apply it to one input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 59 18\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 8\n",
    "VOCABULARY_SIZE = len(character_dict)\n",
    "NUM_NATIONALITIES = len(nationality_dict)\n",
    "\n",
    "print(HIDDEN_DIM, VOCABULARY_SIZE, NUM_NATIONALITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_lstm = SimpleLSTM(HIDDEN_DIM, VOCABULARY_SIZE, NUM_NATIONALITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-2.7548 -3.0228 -2.9007 -2.9889 -3.1759 -2.9469 -3.0174 -2.7576 -2.5518 -2.7996\n",
       "\n",
       "Columns 10 to 17 \n",
       "-2.7950 -2.9458 -2.9164 -2.8029 -2.7879 -3.0171 -2.9504 -3.0852\n",
       "[torch.FloatTensor of size 1x18]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_name = name_to_tensor('sierpinsky')\n",
    "output = simple_lstm(test_name)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an optimizer to be applied to the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(simple_lstm.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now iterate on the inputs and train. We need something that can generate random {name, nationality} pairs. To this end, we create a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_pair(input_dictionary):\n",
    "    nationalities = list(input_dictionary.keys())\n",
    "    nationality = random.choice(nationalities)\n",
    "    name = random.choice(input_dictionary[nationality])\n",
    "    return name_to_tensor(name.lower()), nationality_to_tensor(nationality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must be careful to turn the output names to lowercase, to avoid problems when converting to a tensor, as the character dictionary doesn't comprise uppercase characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 59])\n",
      "torch.Size([1])\n",
      "<class 'torch.autograd.variable.Variable'> <class 'torch.autograd.variable.Variable'>\n"
     ]
    }
   ],
   "source": [
    "test_name, test_nationality = get_random_pair(category_lines)\n",
    "print(test_name.size())\n",
    "print(test_nationality.size())\n",
    "print(type(test_name), type(test_nationality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n",
      "Epoch: 21\n",
      "Epoch: 22\n",
      "Epoch: 23\n",
      "Epoch: 24\n",
      "Epoch: 25\n",
      "Epoch: 26\n",
      "Epoch: 27\n",
      "Epoch: 28\n",
      "Epoch: 29\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "STEPS_PER_EPOCH = 1000\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "k = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        simple_lstm.zero_grad()\n",
    "        simple_lstm.hidden = simple_lstm.init_hidden()\n",
    "        input, target = get_random_pair(category_lines)\n",
    "        output_scores = simple_lstm(input)\n",
    "        loss = loss_function(output_scores, target)\n",
    "        if k % 100 == 0:\n",
    "            loss_history.append(loss.data.numpy()[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the loss has actually decreased during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4345362, 0.45775518, 2.278161, 4.8217554, 2.387222, 2.4770122, 0.15617909, 1.6518058, 0.24032326, 0.0059923823, 0.51312333, 1.8279037, 0.734622, 0.24847049, 0.8013752, 3.178698, 0.082784995, 0.4086973, 1.7454914, 1.4621563, 1.5288228, 2.8329573, 1.7850094, 0.5976076, 2.2369452, 0.13403773, 0.15101944, 0.028004328, 2.571294, 0.5246396, 0.16596869, 2.5890825, 0.5323, 2.4483232, 0.98805803, 0.031101838, 0.033280198, 0.24636875, 1.1190886, 0.3713911, 0.015798736, 1.1042222, 0.41999847, 1.6976091, 2.6918552, 1.7196851, 1.3576381, 2.7320142, 0.83970755, 0.0047142114, 1.4361687, 0.8265884, 4.3237934, 0.4301912, 4.7381263, 4.207761, 2.449709, 2.2202866, 1.8369769, 3.0114343, 1.0969951, 1.109471, 0.9334187, 1.5463387, 1.1602281, 5.619881, 3.4947484, 0.39471126, 0.035193734, 4.226609, 0.61533755, 2.5438633, 0.4348335, 0.7458245, 0.2050372, 0.009121669, 0.63466704, 2.1136425, 0.3441364, 1.0071946, 0.78750646, 0.8561999, 1.9728681, 0.33702397, 0.07361834, 0.16518246, 0.0023275404, 1.3618143, 2.2090147, 0.11919306, 1.6334043, 1.1641603, 0.9936777, 3.208517, 0.98567045, 1.2128537, 2.546632, 0.75125384, 0.003262467, 0.2269688, 0.25450626, 1.9265871, 4.0411787, 0.28705135, 1.6161689, 5.204006, 0.86460996, 0.53602564, 2.3636582, 0.9766577, 2.5273547, 1.8200662, 0.6734514, 0.79997724, 1.0510055, 1.0010473, 0.5848764, 1.6941665, 1.1105089, 6.274147, 1.6005744, 0.22533108, 3.3804727, 0.9563801, 0.010843065, 0.3137258, 0.41089037, 3.2445598, 1.1813937, 0.5343321, 1.800064, 0.67945236, 0.14919864, 1.0573767, 1.3834016, 1.6711783, 1.4424397, 0.3791811, 1.5543892, 0.119774505, 5.786064, 0.09620871, 1.5191016, 1.3759989, 0.8961607, 0.5367028, 0.27945122, 1.0398839, 1.505901, 3.3912795, 1.6278415, 0.4408604, 0.073132694, 0.41514188, 0.23593095, 5.0247955, 1.17446, 0.09507174, 10.329093, 0.64716727, 2.1793194, 0.030755296, 0.68040955, 1.8123285, 0.5524582, 2.0662477, 1.320829, 1.0068823, 0.9780827, 1.7658235, 2.728289, 0.4829017, 1.9405061, 0.5941631, 4.812603, 0.19577186, 0.26729468, 2.0802674, 5.0416536, 2.517573, 2.5815427, 4.3699455, 0.19224758, 1.1490489, 0.3383419, 1.2545335, 0.07465784, 0.060737714, 0.4356242, 2.9059634, 0.5892283, 2.5471673, 0.19603612, 3.9468174, 4.656449, 0.5849688, 1.1917874, 2.1871672, 0.010686807, 0.3922109, 2.764728, 0.45625317, 1.9537255, 0.50493455, 1.8122816, 3.155959, 0.19310626, 0.15127307, 0.5716292, 2.7376285, 1.2382681, 0.007166277, 2.9148288, 1.1805066, 0.5728905, 0.27392504, 0.6172587, 0.0086249625, 1.6793796, 1.2730938, 1.0111272, 0.82215774, 0.2840023, 1.8207318, 1.3184868, 1.2586746, 0.38202447, 2.115025, 2.1039135, 0.3929656, 3.7813122, 1.0623628, 2.0452464, 1.5991045, 0.88850886, 0.43286368, 3.320683, 0.18279567, 1.6642635, 3.70085, 1.8547025, 1.4926834, 0.90861124, 0.23788711, 0.007790212, 0.44053596, 0.93015367, 1.4902924, 3.7219641, 0.20062163, 0.22810861, 1.0394361, 1.2865033, 2.146861, 2.295862, 0.8205291, 3.3517764, 1.9784782, 0.16199893, 2.4348235, 0.27629328, 0.13067117, 2.7457666, 1.4799744, 2.6962945, 2.8257287, 4.0366936, 1.1142533, 0.60197026, 3.3736413, 1.0068961, 0.067888446, 2.0332236, 2.9172266, 2.6333158, 0.35312846, 2.064409, 1.029498, 1.4969449, 0.014179637, 1.4258411, 1.1906163, 2.080821, 0.31820446, 3.3690734, 1.682776, 1.0925826, 5.633919, 0.5196398, 0.8277763, 0.024437893, 1.5409033, 0.79763764, 0.29620153, 1.7513325, 2.0029392, 1.6376553, 2.6646855, 2.8094451, 0.00392615]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f53fd853860>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f53fd78e2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(loss_history)\n",
    "plt.plot(range(len(loss_history)), loss_history, 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a prediction on the trained model. We revert the nationality dictionary and create a utility function that prints the output indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_nationality = {ix: nationality for nationality, ix in nationality_dict.items()}\n",
    "\n",
    "def print_predicted_classes(name, k=3):\n",
    "    name = name_to_tensor(name)\n",
    "    class_score = simple_lstm(name)\n",
    "    val, idx = class_score.topk(k, 1)\n",
    "    idx = idx.data.numpy().flatten()\n",
    "    for i in idx:\n",
    "        print(ix_to_nationality[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predicted_classes('ferrauto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predicted_classes('van der waals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predicted_classes('soares')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predicted_classes('yamamoto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predicted_classes('dermitzakis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predicted_classes('messner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
