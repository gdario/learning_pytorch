{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LSTM in PyTorch\n",
    "\n",
    "## Building a simple vocabulary from a collection of sentences\n",
    "\n",
    "In PyTorch the input to an LSTM is expected to be a 3D tensor. Suppose we have a collection of sentences as an input. Let's start from the very beginning, showing how to go from a collection of strings to a vocabulary organized as a Python dictionary. As a simplification, all the sentences contain the same number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'had', 'breakfast', 'this', 'morning'], ['then', 'I', 'took', 'a', 'walk'], ['but', 'the', 'weather', 'was', 'bad']]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "sentences = ['I had breakfast this morning'.split(' '),\n",
    "             'then I took a walk'.split(' '),\n",
    "             'but the weather was bad'.split(' ')]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a vocabulary turning each sentence into a set, and then iteratively taking the union of the sets. This will provide us with a single set with the unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this', 'but', 'walk', 'bad', 'a', 'then', 'was', 'weather', 'I', 'had', 'breakfast', 'took', 'morning', 'the'}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = reduce(set.union, [set(sentence) for sentence in sentences])\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily turn this set into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 0, 'but': 1, 'walk': 2, 'bad': 3, 'a': 4, 'then': 5, 'was': 6, 'weather': 7, 'I': 8, 'had': 9, 'breakfast': 10, 'took': 11, 'morning': 12, 'the': 13}\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {word: ix for ix, word in enumerate(list(vocabulary))}\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to turn the sentences into NumPy arrays that can be passed to the LSTM model. We start pre-allocating a numpy array of zeroes with shape (number of sentences, maximum length of a sentence, number of words in the vocabulary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 14)\n"
     ]
    }
   ],
   "source": [
    "sentence_max_length = max([len(sentence) for sentence in sentences])\n",
    "inputs = np.zeros((len(sentences), sentence_max_length, len(vocabulary)), dtype='float32')\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then populate this array with a one hot encoder (this would not work if we wanted to create word embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n",
      "(3, 5, 14)\n"
     ]
    }
   ],
   "source": [
    "for ix_sentence in range(len(sentences)):\n",
    "    for ix_word in range(len(sentences[ix_sentence])):\n",
    "        ix_vocab = vocabulary[sentences[ix_sentence][ix_word]]\n",
    "        inputs[ix_sentence, ix_word, ix_vocab] = 1\n",
    "\n",
    "print(inputs)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the correct shape\n",
    "\n",
    "Our inputs consist in three sequences each one-hot encoded into a numpy array of size 5 x 14. We can now introduce an LSTM module that will read these sequences and store the state in a hidden layer of size 5.\n",
    "From the [documentation of the LSTM layer](http://pytorch.org/docs/master/nn.html#torch.nn.LSTM) we see that the inputs are supposed to be of shape (seq_len, batch, input_size). Here we are providing batches of size 1, which means that we will need to reshape each input to (5, 1, 14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(3, 1, 5, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now instatiate an LSTM layer with 4 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=14, hidden_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of the hidden and cell states\n",
    "\n",
    "From the [documentation of the LSTM layer](http://pytorch.org/docs/master/nn.html#torch.nn.LSTM), LSTM returns a tuple containing the outputs and a tuple with the hidden hidden state and the cell state, and receives in input the input sequences and, optionally, the same tuple. If this is not provided, it will default to a zero initialization for both the hidden and the cell states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 5, 14])\n"
     ]
    }
   ],
   "source": [
    "input_var = autograd.Variable(torch.from_numpy(inputs))\n",
    "print(input_var.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the LSTM layer is actually working by assigning the output of `lstm` applied to the first sequence. Here, even if it is not necessary, we provide a manually zero-initialized tuple of hidden and cell states, to show the full syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = (autograd.Variable(torch.zeros(1, 1, 4)), \n",
    "          autograd.Variable(torch.zeros(1, 1, 4)))\n",
    "out, hidden = lstm(input_var[0], hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output has shape while the hidden and cell states have shapes respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([1, 5, 4])\n",
      "Hidden sizes: torch.Size([1, 5, 4]) and torch.Size([1, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "print('Output size: {}'.format(out.size()))\n",
    "print('Hidden sizes: {0} and {1}'.format(hidden[0].size(), hidden[1].size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 5 elements in the sentence, we have the output of the 4 hidden/cell states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM for part-of-speech tagging\n",
    "\n",
    "We have an input sentence formed by the words $w_1, w_1, \\ldots, w_M$ for $w_i \\in V$. Each word is associated with a tag $\\hat y_i$, which might indicate, for example, whether the word is a verb, a noun etc. Let's call the set of all the possible tags $T$. We assign a unique index to each tag, and we use an LSTM to predict, for each word, the corresponding tag. If we call $h_i$ the hidden state of the LSTM at step $i$, we select $\\hat y_i = \\mathrm{argmax}_j (\\log \\mathrm{Softmax}(A h_i + b))_j$. We start defining a simple function to convert a sequence into indices. In the [PyTorch LSTM tutorial](http://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#sphx-glr-beginner-nlp-sequence-models-tutorial-py) they use a particularly simple approach: the word-to-index mapping consists simply in associating to each new word an index equal to the current length of the mapping itself. Each new word makes the mapping longer, and is therefore associated with an increasingly larger integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a simple function to map a sequence to a tensor (a Variable, to be precise) of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       "[torch.LongTensor of size 5]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return autograd.Variable(tensor)\n",
    "\n",
    "tag_to_ix = {'DET': 0, 'V': 1, 'NN': 2}\n",
    "\n",
    "prepare_sequence(training_data[0][0], word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same type of representation used for Embedding layers, and this is not a coincidence, since we will be using an embedding layer as an input to the LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, target_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, target_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)))\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through this class step by step:\n",
    "\n",
    "1. We start defining the word embeddings. No surprises here.\n",
    "2. We define an LSTM layer which receives inputs of size `embedding_dim` and produces outputs of size `hidden_dim`.\n",
    "3. A FC layer that goes from the hidden units to the output, i.e. the tags.\n",
    "4. This is a bit surprising at first. If you remember above, we needed to pass the initial value of the hidden layer and of the cell status. This becomes an attribute of the class, and is initialized via the `init_hidden()` method. This allows to re-initialize the hidden states of an instance of this class as shown below.\n",
    "\n",
    "The `forward` method is pretty clear:\n",
    "\n",
    "1. The input sentence is converted into an embedding.\n",
    "2. The LSTM returns its output in `lstm_out` while the hidden states stored in `self.hidden` are updated.\n",
    "3. `lstm_out` becomes, after adequate reshaping, the input of the FC layer `hidden2tag`.\n",
    "4. The final log-softmax of the tags are computed for each word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.7757 -1.3122 -1.3078\n",
      "-0.8132 -1.2804 -1.2778\n",
      "-0.8048 -1.2743 -1.2976\n",
      "-0.7742 -1.2807 -1.3429\n",
      "-0.7743 -1.3346 -1.2883\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Variable containing:\n",
      "-0.9134 -1.5046 -0.9763\n",
      "-1.0410 -1.3724 -0.9329\n",
      "-1.0367 -1.3037 -0.9839\n",
      "-0.9645 -1.3409 -1.0294\n",
      "-1.0116 -1.3938 -0.9461\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovenko/miniconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Before training\n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "print(tag_scores)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    for sentence, tags in training_data:\n",
    "        model.zero_grad()\n",
    "        model.hidden = model.init_hidden()\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets_in = prepare_sequence(tags, tag_to_ix)\n",
    "        tag_scores = model(sentence_in)\n",
    "        loss = criterion(tag_scores, targets_in)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "tag_scores = model(inputs)\n",
    "print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      "[torch.LongTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "print(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
